as.ppp(ppp(long,lat,window=win))#
}#
load("afg.data")#
#
afg <- afg.data#
spatstat.options(checkpolygons = FALSE) #
afg$data <- afg$data[!is.na(afg$data$Latitude),]
data.frame(0:nrow(dd)
)
ls
quit()
library(infochimps)
chimps<-infochimps("vv5cbsDQRvWcuwAhgfiXkLHLx69")
strong.links("drewconway",chimps)
library(igraph)
G<-graph.data.frame(strong.links("drewconway",ses))
G<-graph.data.frame(strong.links("drewconway",chimps))
G
summary(G)
e
?new.env
?.onLoad
h$data<-list()
h<-new.env()
h$data<-list()
h$dat
h$data
h
h$data<-list(cocks="big",tits=)
h$data<-list(cocks="big",tits="massive")
h$data$cocks
library(twitteR)#
library(infochimps)#
library(datamap)#
#
infochimps('vv5cbsDQRvWcuwAhgfiXkLHLx69')#
#
# Creates a new mapper, similar to an OO class#
newMapper(type='twitchimps:influence',#
#
# Init is called once during newMap(). Note that#
# since it's called only once, your friend list, wether you#
# add or drop some later, will stay constant.#
init = function(map,user){#
install(#
unlist(lapply(userFriends(user), function(n) screenName(n))),#
map#
)#
TRUE#
},#
#
# Get is called real-time on each access to the variable#
get = function(user) influence(user)#
)#
#
#
# Install the map at position 2 on the search path#
mapAttach(newMap('twitchimps:influence','YOUR_TWITTER_NAME_HERE'),pos=2)#
#
# List all your friends#
ls(2)
install.packages("datamap",dependencies=TRUE)
library(twitteR)#
library(infochimps)#
library(datamap)#
#
infochimps('vv5cbsDQRvWcuwAhgfiXkLHLx69')#
#
# Creates a new mapper, similar to an OO class#
newMapper(type='twitchimps:influence',#
#
# Init is called once during newMap(). Note that#
# since it's called only once, your friend list, wether you#
# add or drop some later, will stay constant.#
init = function(map,user){#
install(#
unlist(lapply(userFriends(user), function(n) screenName(n))),#
map#
)#
TRUE#
},#
#
# Get is called real-time on each access to the variable#
get = function(user) influence(user)#
)#
#
#
# Install the map at position 2 on the search path#
mapAttach(newMap('twitchimps:influence','YOUR_TWITTER_NAME_HERE'),pos=2)#
#
# List all your friends#
ls(2)
install.packages("twitteR",dependencies=TRUE)
library(twitteR)#
library(infochimps)#
library(datamap)#
#
infochimps('vv5cbsDQRvWcuwAhgfiXkLHLx69')#
#
# Creates a new mapper, similar to an OO class#
newMapper(type='twitchimps:influence',#
#
# Init is called once during newMap(). Note that#
# since it's called only once, your friend list, wether you#
# add or drop some later, will stay constant.#
init = function(map,user){#
install(#
unlist(lapply(userFriends(user), function(n) screenName(n))),#
map#
)#
TRUE#
},#
#
# Get is called real-time on each access to the variable#
get = function(user) influence(user)#
)#
#
#
# Install the map at position 2 on the search path#
mapAttach(newMap('twitchimps:influence','YOUR_TWITTER_NAME_HERE'),pos=2)#
#
# List all your friends#
ls(2)
library(twitteR)#
library(infochimps)#
library(datamap)
library(twitteR)#
library(infochimps)#
library(datamap)#
#
infochimps('vv5cbsDQRvWcuwAhgfiXkLHLx69')#
#
# Creates a new mapper, similar to an OO class#
newMapper(type='twitchimps:influence',#
#
# Init is called once during newMap(). Note that#
# since it's called only once, your friend list, wether you#
# add or drop some later, will stay constant.#
init = function(map,user){#
install(#
unlist(lapply(userFriends(user), function(n) screenName(n))),#
map#
)#
TRUE#
},#
#
# Get is called real-time on each access to the variable#
get = function(user) influence(user)#
)#
#
#
# Install the map at position 2 on the search path#
mapAttach(newMap('twitchimps:influence','drewconway'),pos=2)#
#
# List all your friends#
ls(2)
ls()
ls(1)
ls(2)
library(twitteR)#
library(infochimps)#
library(datamap)#
#
infochimps('vv5cbsDQRvWcuwAhgfiXkLHLx69')#
#
# Creates a new mapper, similar to an OO class#
newMapper(type='twitchimps:influence',#
#
# Init is called once during newMap(). Note that#
# since it's called only once, your friend list, wether you#
# add or drop some later, will stay constant.#
init = function(map,user){#
install(#
unlist(lapply(userFriends(user), function(n) screenName(n))),#
map#
)#
TRUE#
},#
#
# Get is called real-time on each access to the variable#
get = function(user) influence(user)#
)#
#
#
# Install the map at position 2 on the search path#
mapAttach(newMap('twitchimps:influence','drewconway'),pos=2)#
#
# List all your friends#
ls(2)#
#
# Their names are now variables. Enter one at the R prompt and see that#
# it contains their infochimps influence.#
#
# Create a data frame. You may want to use head(ls(2)) instead of ls(2)#
# if you have quite a few followers.#
#
x <- data.frame()#
lapply(#
ls(2),#
function(i){#
y <- get(i)#
if(!is.na(y))#
x <<- rbind(x,as.data.frame(y))#
}#
)#
#
summary(x)
exp((21-1.1*log(1563)))
library(liglimn)
library(biglm)
?biglm
library("twitteR")
publicTimeline()
t<-publicTimeline()
20*20
20*25
publicTimeline(500)
?publicTimeline
library(tm)
pub.time<-publicTimeline(n=500()
)
pub.time<-publicTimeline(n=500)
pub.time<-publicTimeline()
pub.time<-sapply(1:25,fuction(x) publicTimeline)
publicTimeline(n=100)
rand.pub<-list()
for(i in 1:500) { rand.pub[[i]]<-publicTimeline(n=1)}
rand.pub
?append
rand.pub<-list()
data("economics")
library(reshape)
data("economics")
library(ggplot2)
data("economics")
economics
head(economics)
dat.m<-melt(economics, measure.cars=c("pop","unemploy"))
dat.m<-melt(economics, measure.vars=c("pop","unemploy"))
head(dat.m)
ggplot(dat.m, aes(x=date, y=value)) + geom_line() + facet_grid(variable~., scales="free_y")
q()
?ReferenceClasses
?install.packages
?colSums
?transform
?matrix
library("tm")
library("XML")
readHTMLTable("http://www.poliscijobrumors.com/forum.php?id=1")
library(XML)
library(Rack)
s <- Rhttpd$new()
s$launch(name="wordCloud", app="~/Downloads/rerapacheforawebapp/twc_handler.R")
library(RCurl)
library(RJSONIO)
URLencode("R hacks")
?URLencode
library(RCurl)
library(RJSONIO)
test<-getURL("http://api.infochimps.com/economics/finance/stocks/y_historical/price_range?symbol=AAPL&beg_date=20010810&end_date=20010810&apikey=vv5cbsDQRvWcuwAhgfiXkLHLx69")
test
fromJSON(test)
fromJSON(test)$results
fromJSON(test)$results[[1]]
strptime("20010810", format="%Y%m%d")
strptime("2001081sd0", format="%Y%m%d")
strptime("2001081000", format="%Y%m%d")
strptime("2001", format="%Y%m%d")
all.names<-c("exchange","symbol","date","open","close","adj_close","low","high","volume")
all.names
yahoo.stocks <- #
function(symbol, begin.date, end.date, from=0, to.df=TRUE) {#
    if(is.na(strptime(begin.date, format="%y%m%d")) | is.na(strptime(end.date, format="%y%m%d"))) {#
        warning("One or both of the date strings is malformed. Must be YYYYMMdd format.")#
    }#
    else {#
        stocks.url<-paste(.InfochimpsEnv$data$finance,"stocks/y_historical/price_range.json_from=",from,"&symbol=",#
            URLencode(symbol),"&begin_data=",begin.data,"&end_date=",end.date,"&apikey=",.InfochimpsEnv$data$api.key,sep="")#
        stocks.get<-getURL(stocks.url)#
        stocks.get<-clean.george(stocks.get)#
        stocks.data<-fromJSON(stocks.get)#
        if(is.null(stocks.data$results[[1]])) {#
            warning("Something has gone wrong, please check your stock search")#
            return(NA)#
        }#
        else {#
            if(to.df) {#
                all.names<-c("exchange","symbol","date","open","close","adj_close","low","high","volume")#
                return(jsonToDataFrame(stocks.data, all.names))#
            }#
            else {#
                return(stocks.data)#
            }#
        }#
    }#
}
yahoo.stocks
?stop
stop("cocks")
?identify
1000/2
1000/20
950
900
seq(50,1000,50)
length(seq(50,1000,50))
1/20
1/1000
d<-c(25)
test<-seq(50,950,50)
c(d,testy)
c(d,test)
length(c(d,test))
library(ggplot2)
library(igraph)
?with
library(compiler)
install.packages("~/Documents/Code/R/stalkR/")
install.packages("~/Documents/Code/R/stalkR/stalkR_0.01.tar.gz", repos=NULL, type="source")
library(stalkR)
my.locs<-get.mylocations("agconway","Drew Conway's iPhone")
install.packages("~/Documents/Code/R/stalkR/stalkR_0.01.tar.gz", repos=NULL, type="source")
library(stalkR)
my.locs<-get.mylocations("agconway", "Drew Conway's iPhone")
install.packages("~/Documents/Code/R/stalkR/stalkR_0.01.tar.gz", repos=NULL, type="source")
library(stalkR)
my.locs<-get.mylocations("agconway","Drew Conway's iPhone")
system.fil()
system.file()
.path.package("igraph")
.path.package("stalkR")
library(stalkR)
my.locs<-get.mylocations("agconway","Drew Conway's iPhone")
viz.locations(my.locs,"state", "connecticut")
summary(my.locs)
viz.locations(my.locs,"cities", "new york")
viz.locations(my.locs,"us cities", "new york")
?.Platform
.Platform()
.Platform
R.Version()
R.Version() >= 2.13.0
?R.Version()
R.version
R.version$major
library(stalkR)
my.locs<-get.mylocations("agconway","Drew Conway's iPhone")
summary(my.locs)
times<-my.locs$Timestamp[1:100]
times
strptime(times, "UTC")
?strptime
as.POSIXct(times)
as.POSIXct(times, origin="1970-01-01")
as.POSIXlt(times, origin="1970-01-01")
as.POSIXlt(times, origin="2001-01-01")
as.POSIXct(times, origin="2001-01-01")
as.POSIXct(times, origin="2001-01-01", tz="America/New York")
viz.locations(my.locs, "state", "dc")
viz.locations(my.locs, "state", "california")
library(stalkR)
drew.locs<-get.mylocations("agconway", "Drew Conway's iPhone")
viz.locations(drew.locs, "state", "new york")
viz.locations(drew.locs, "state", "virginia")
viz.locations(drew.locs, "state", "california")
viz.locations(drew.locs, "state")
viz.locations(drew.locs, "world")
setwd('/Users/agconway/Documents/GMM/GMM/examples/simulations/barabasi_albert')
# File-Name:       ba_analysis.R           #
# Date:            2011-04-07                                #
# Author:          Drew Conway#
# Email:           drew.conway@nyu.edu                                      #
# Purpose:         Statistically explore the results of the Barabasi-Albert GMM models#
# Data Used:       Output from barabasi_albert.py#
# Packages Used:   igraph, ggplot2#
# Output File:    #
# Data Output:     #
# Machine:         Drew Conway's MacBook Pro#
#
# Copyright (c) 2011, under the Simplified BSD License.  #
# For more information on FreeBSD see: http://www.opensource.org/licenses/bsd-license.php#
# All rights reserved.                                                         #
#
# Load libraries#
library(igraph)#
library(ggplot2)#
library(stats4)#
#
# A function that retuns the scaling parameter for the degree #
# distribution of a given igraph network#
get.scaling<-function(graph) {#
    d<-degree(graph)#
    x<-0:max(d)#
    dd<-c(0,hist(d, plot=FALSE, breaks=x)$counts)#
    dd.log<-ifelse(dd<1,0,log10(dd))#
    x.log<-ifelse(x<1,0,log10(x))#
    dd.fit<-lm(dd.log ~ x.log)#
    return(as.numeric(dd.fit$coeff)[2])#
}#
#
# A function that returns a vector of c(m, base_size, scaling) for#
# some graphml file produced by a Barabasi-Albert GMM simulation#
ba.test<-function(file) {#
    g<-read.graph(file, format="graphml")#
    params<-strsplit(file,"[_.]")#
    return(c(params[[1]][5],params[[1]][6],get.scaling(g)))#
}#
#
base.test<-function(file) {#
    g<-read.graph(file, format="graphml")#
    params<-strsplit(file,"[_.]")#
    return(c(params[[1]][2],get.scaling(g)))#
}#
#
get.plfit<-function(file, base=FALSE) {#
    g<-read.graph(file, format="graphml")#
    deg<-degree(g)#
    graph.name<-strsplit(file, "[/_.]")#
    if(base) {#
        return(c(graph.name[[1]][3],graph.name[[1]][4],coef(power.law.fit(deg))))#
    }#
    else {#
        return(c(graph.name[[1]][7],graph.name[[1]][8],coef(power.law.fit(deg))))#
    }#
}#
#
#
# All network files#
sim.dir<-"data/simulated/"#
sim.files<-names(file.access(dir(sim.dir)))#
#
base.dir<-"data/base/"#
base.files<-names(file.access(dir(base.dir)))#
#
# Get scaling data for all simulations#
scaling.data<-lapply(sim.files, function(f) ba.test(paste(sim.dir,f,sep="")))#
scaling.matrix<-do.call(rbind, scaling.data)#
scaling.df<-data.frame(scaling.matrix, stringsAsFactors=FALSE)#
#
# Clean up#
names(scaling.df)<-c("m","base.size","scaling")#
scaling.df$m<-as.factor(scaling.df$m)#
scaling.df$base.size<-as.numeric(scaling.df$base.size)#
scaling.df$scaling<-abs(as.numeric(scaling.df$scaling))#
scaling.df<-scaling.df[with(scaling.df, order(m,base.size)),]#
#
#
# Now do the same for a bunch of simulated BA networks#
base.data<-lapply(base.files, function(f) base.test(paste(base.dir,f,sep="")))#
base.matrix<-do.call(rbind, base.data)#
base.df<-data.frame(base.matrix, stringsAsFactors=FALSE)#
#
# Clean up#
names(base.df)<-c("m","scaling")#
base.df$m<-as.factor(base.df$m)#
base.df$scaling<-abs(as.numeric(base.df$scaling))#
base.df<-base.df[with(base.df, order(m)),]#
#
#
# Next, use MLE to estimate the PL fit#
alpha.sims<-lapply(sim.files, function(f) get.plfit(paste(sim.dir,f,sep="")))#
alpha.sims.matrix<-do.call(rbind, alpha.sims)#
alpha.sims.df<-data.frame(alpha.sims.matrix, stringsAsFactors=FALSE)#
names(alpha.sims.df)<-c("m", "base.size", "alpha")#
alpha.sims.df$m<-as.factor(alpha.sims.df$m)#
alpha.sims.df$base.size<-as.numeric(alpha.sims.df$base.size)#
alpha.sims.df$alpha<-as.numeric(alpha.sims.df$alpha)#
#
alpha.base<-lapply(base.files, function(f) get.plfit(paste(base.dir,f,sep=""), base=TRUE))#
alpha.base.matrix<-do.call(rbind, alpha.base)#
alpha.base.df<-data.frame(alpha.base.matrix, stringsAsFactors=FALSE)#
names(alpha.base.df)<-c("id", "m", "alpha")#
alpha.base.df$id<-as.numeric(alpha.base.df$id)#
alpha.base.df$m<-as.factor(alpha.base.df$m)#
alpha.base.df$alpha<-as.numeric(alpha.base.df$alpha)
setwd('/Users/agconway/Documents/GMM/GMM/examples/simulations/barabasi_albert')
#
# m=1 plot#
m1.plot<-ggplot(subset(base.df, m==1), aes(x=scaling))+stat_density(aes(fill="BA", alpha=.65))+#
    stat_density(data=subset(scaling.df, m==1), aes(x=scaling, fill="GMM",alpha=.65))+#
    scale_fill_manual(values=c("BA"="darkred", "GMM"="darkblue"), name="Model type")+#
    scale_alpha(legend=FALSE)+scale_x_continuous(limits=c(-2,0))+#
    opts(title="Comparison between Barabasi-Albert Random\nGraph Model and GMM Equivalent [n=100, m=1]")+#
    xlab("Scaling parameter")+#
    ylab("Density")+#
    theme_bw()#
ggsave(plot=m1.plot, filename="m1.pdf", height=7, width=11)#
    #
# m=3 plot#
m3.plot<-ggplot(subset(base.df, m==3), aes(x=scaling))+stat_density(aes(fill="BA", alpha=.65))+#
    stat_density(data=subset(scaling.df, m==3), aes(x=scaling, fill="GMM",alpha=.65))+#
    scale_fill_manual(values=c("BA"="darkred", "GMM"="darkblue"), name="Model type")+#
    scale_alpha(legend=FALSE)+scale_x_continuous(limits=c(-2,0))+#
    opts(title="Comparison between Barabasi-Albert Random\nGraph Model and GMM Equivalent [n=100, m=3]")+#
    xlab("Scaling parameter")+#
    ylab("Density")+#
    theme_bw()#
ggsave(plot=m3.plot, filename="m3.pdf", height=7, width=11)#
#
# m=5 plot#
m5.plot<-ggplot(subset(base.df, m==5), aes(x=scaling))+stat_density(aes(fill="BA", alpha=.65))+#
    stat_density(data=subset(scaling.df, m==5), aes(x=scaling, fill="GMM",alpha=.65))+#
    scale_fill_manual(values=c("BA"="darkred", "GMM"="darkblue"), name="Model type")+#
    scale_alpha(legend=FALSE)+scale_x_continuous(limits=c(-2,0))+#
    opts(title="Comparison between Barabasi-Albert Random\nGraph Model and GMM Equivalent [n=100, m=5]")+#
    xlab("Scaling parameter")+#
    ylab("Density")+#
    theme_bw()#
ggsave(plot=m5.plot, filename="m5.pdf", height=7, width=11)#
#
# m=7 plot#
m7.plot<-ggplot(subset(base.df, m==7), aes(x=scaling))+stat_density(aes(fill="BA", alpha=.65))+#
    stat_density(data=subset(scaling.df, m==7), aes(x=scaling, fill="GMM",alpha=.65))+#
    scale_fill_manual(values=c("BA"="darkred", "GMM"="darkblue"), name="Model type")+#
    scale_alpha(legend=FALSE)+scale_x_continuous(limits=c(-2,0))+#
    opts(title="Comparison between Barabasi-Albert Random\nGraph Model and GMM Equivalent [n=100, m=7]")+#
    xlab("Scaling parameter")+#
    ylab("Density")+#
    theme_bw()#
ggsave(plot=m7.plot, filename="m7.pdf", height=7, width=11)#
#
# Repeat for MLE estimates#
m1.alpha.plot<-ggplot(subset(alpha.base.df, m==1), aes(x=alpha))+stat_density(aes(fill="BA", alpha=.65))+#
    stat_density(data=subset(alpha.sims.df, m==1), aes(x=alpha, fill="GMM",alpha=.65))+#
    scale_fill_manual(values=c("BA"="darkred", "GMM"="darkblue"), name="Model type")+#
    scale_alpha(legend=FALSE)+scale_x_continuous(limits=c(1,3))+#
    opts(title="Comparison between Barabasi-Albert Random\nGraph Model and GMM Equivalent [n=100, m=1]")+#
    xlab("MLE Power-law Alpha Estimate")+#
    ylab("Density")+#
    theme_bw()#
ggsave(plot=m1.alpha.plot, filename="m1_alpha.pdf", height=7, width=11)#
#
m3.alpha.plot<-ggplot(subset(alpha.base.df, m==3), aes(x=alpha))+stat_density(aes(fill="BA", alpha=.65))+#
    stat_density(data=subset(alpha.sims.df, m==3), aes(x=alpha, fill="GMM",alpha=.65))+#
    scale_fill_manual(values=c("BA"="darkred", "GMM"="darkblue"), name="Model type")+#
    scale_alpha(legend=FALSE)+scale_x_continuous(limits=c(1,3))+#
    opts(title="Comparison between Barabasi-Albert Random\nGraph Model and GMM Equivalent [n=100, m=3]")+#
    xlab("MLE Power-law Alpha Estimate")+#
    ylab("Density")+#
    theme_bw()#
ggsave(plot=m3.alpha.plot, filename="m3_alpha.pdf", height=7, width=11)#
#
m5.alpha.plot<-ggplot(subset(alpha.base.df, m==5), aes(x=alpha))+stat_density(aes(fill="BA", alpha=.65))+#
    stat_density(data=subset(alpha.sims.df, m==5), aes(x=alpha, fill="GMM",alpha=.65))+#
    scale_fill_manual(values=c("BA"="darkred", "GMM"="darkblue"), name="Model type")+#
    scale_alpha(legend=FALSE)+scale_x_continuous(limits=c(1,3))+#
    opts(title="Comparison between Barabasi-Albert Random\nGraph Model and GMM Equivalent [n=100, m=5]")+#
    xlab("MLE Power-law Alpha Estimate")+#
    ylab("Density")+#
    theme_bw()#
ggsave(plot=m5.alpha.plot, filename="m5_alpha.pdf", height=7, width=11)#
#
m7.alpha.plot<-ggplot(subset(alpha.base.df, m==7), aes(x=alpha))+stat_density(aes(fill="BA", alpha=.65))+#
    stat_density(data=subset(alpha.sims.df, m==7), aes(x=alpha, fill="GMM",alpha=.65))+#
    scale_fill_manual(values=c("BA"="darkred", "GMM"="darkblue"), name="Model type")+#
    scale_alpha(legend=FALSE)+scale_x_continuous(limits=c(1,3))+#
    opts(title="Comparison between Barabasi-Albert Random\nGraph Model and GMM Equivalent [n=100, m=7]")+#
    xlab("MLE Power-law Alpha Estimate")+#
    ylab("Density")+#
    theme_bw()#
ggsave(plot=m7.alpha.plot, filename="m7_alpha.pdf", height=7, width=11)
